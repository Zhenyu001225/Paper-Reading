Title: [018][Robustness and Efficiency][Sparsity and Robustness] Adversarial Neural Pruning with Latent Vulnerability Suppression
Authors:  Divyam Madaan, Jinwoo Shin, Sung Ju Hwang
Affiliations: KAIST
Venue: ICML 2020
Link: http://proceedings.mlr.press/v119/madaan20a.html
Code Link: https://github.com/divyam3897/ANP_VS
Summary:
This paper defines the vulnerable feature of DNNs, and designs an algorithm for detecting the feature and eliminating the features with high vulnerability.
Problem:

The adversarial vulnerability of a DNN comes from the distortion in the latent feature space incurred by the adversarial perturbation. But not all features are vulnerable, just some features may have more substantial distortion. How to find the vulnerable features to suppress the distortion and eliminate the vulnerability?

Key ideas:

Sparse networks can have a much smaller degree of network-level vulnerability. Just suppress vulnerability by pruning the latent features with high vulnerability.
Solutions:
Propose a Bayesian formulation that trains a Bayesian pruning (dropout) mask for the adversarial robustness of the network. Then introduced Vulnerability Suppression (VS) loss, which minimizes network vulnerability.
Firstly, define the vulnerability of the features in the neural network. It is defined as the expectation of the Manhattan distance between the feature value for a clean example and an adversarial example. Then, combine the mask and the adversarial training as the pruning method.The final optimization object is the classification loss and the vulnerability suppression loss.
Strengths & Weaknesses:
Strengths: The question of definitions is interesting, and this explanation can be referred to.
Takeaways&How can I do better:

Can give some purpose and meaning to the mask by defining some other loss to the final optimization object.
